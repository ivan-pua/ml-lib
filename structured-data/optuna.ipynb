{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66feedbe",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning with Optuna\n",
    "Purpose: To select the best classifier model and hyperparameters\n",
    "\n",
    "Data: [Telco Churn Data](https://www.kaggle.com/datasets/blastchar/telco-customer-churn)\n",
    "\n",
    "Metric: Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5334507e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sklearn\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f38ebb4",
   "metadata": {},
   "source": [
    "# Optuna\n",
    "\n",
    "Option 1: AdaBoost \n",
    "\n",
    "Option 2: LogisticRegressionCV\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "99bb20df",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('preprocessed.csv') #insert dataset here\n",
    "\n",
    "y = df.pop('Churn')\n",
    "X = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "56a49d03",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-09-06 20:24:14,715]\u001b[0m A new study created in memory with name: no-name-365e0396-9684-4f56-82ca-80a980bad6b9\u001b[0m\n",
      "\u001b[32m[I 2022-09-06 20:24:15,247]\u001b[0m Trial 0 finished with value: 0.2601279317697228 and parameters: {'classifier': 'AdaBoost', 'n_estimators': 350, 'learning_rate': 2.6820523278655486}. Best is trial 0 with value: 0.2601279317697228.\u001b[0m\n",
      "\u001b[32m[I 2022-09-06 20:24:16,446]\u001b[0m Trial 1 finished with value: 0.8002842928216063 and parameters: {'classifier': 'AdaBoost', 'n_estimators': 320, 'learning_rate': 1.4970886285073715}. Best is trial 1 with value: 0.8002842928216063.\u001b[0m\n",
      "\u001b[32m[I 2022-09-06 20:24:16,672]\u001b[0m Trial 2 finished with value: 0.7981520966595593 and parameters: {'classifier': 'AdaBoost', 'n_estimators': 60, 'learning_rate': 1.737100491636285}. Best is trial 1 with value: 0.8002842928216063.\u001b[0m\n",
      "<timed exec>:20: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "/Users/ivanpua/opt/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-09-06 20:24:16,774]\u001b[0m Trial 3 finished with value: 0.7398720682302772 and parameters: {'classifier': 'Logistic', 'penalty': 'l1', 'logistic-regularization': 7.601493359885958}. Best is trial 1 with value: 0.8002842928216063.\u001b[0m\n",
      "\u001b[32m[I 2022-09-06 20:24:17,095]\u001b[0m Trial 4 finished with value: 0.26723525230987916 and parameters: {'classifier': 'AdaBoost', 'n_estimators': 150, 'learning_rate': 2.0895701836846743}. Best is trial 1 with value: 0.8002842928216063.\u001b[0m\n",
      "\u001b[32m[I 2022-09-06 20:24:17,538]\u001b[0m Trial 5 finished with value: 0.2601279317697228 and parameters: {'classifier': 'AdaBoost', 'n_estimators': 300, 'learning_rate': 2.5555754115536637}. Best is trial 1 with value: 0.8002842928216063.\u001b[0m\n",
      "\u001b[32m[I 2022-09-06 20:24:19,097]\u001b[0m Trial 6 finished with value: 0.7981520966595593 and parameters: {'classifier': 'AdaBoost', 'n_estimators': 420, 'learning_rate': 0.3580994869358526}. Best is trial 1 with value: 0.8002842928216063.\u001b[0m\n",
      "<timed exec>:20: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "/Users/ivanpua/opt/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-09-06 20:24:19,200]\u001b[0m Trial 7 finished with value: 0.7398720682302772 and parameters: {'classifier': 'Logistic', 'penalty': 'l1', 'logistic-regularization': 4.282293779944155}. Best is trial 1 with value: 0.8002842928216063.\u001b[0m\n",
      "\u001b[32m[I 2022-09-06 20:24:20,725]\u001b[0m Trial 8 finished with value: 0.7974413646055437 and parameters: {'classifier': 'AdaBoost', 'n_estimators': 410, 'learning_rate': 0.5650733279932172}. Best is trial 1 with value: 0.8002842928216063.\u001b[0m\n",
      "\u001b[32m[I 2022-09-06 20:24:21,654]\u001b[0m Trial 9 finished with value: 0.8017057569296375 and parameters: {'classifier': 'AdaBoost', 'n_estimators': 250, 'learning_rate': 1.2763185629099136}. Best is trial 9 with value: 0.8017057569296375.\u001b[0m\n",
      "<timed exec>:20: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "/Users/ivanpua/opt/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "\u001b[32m[I 2022-09-06 20:24:21,733]\u001b[0m Trial 10 finished with value: 0.7874911158493249 and parameters: {'classifier': 'Logistic', 'penalty': 'l2', 'logistic-regularization': 0.10696367760326009}. Best is trial 9 with value: 0.8017057569296375.\u001b[0m\n",
      "\u001b[32m[I 2022-09-06 20:24:22,539]\u001b[0m Trial 11 finished with value: 0.8031272210376688 and parameters: {'classifier': 'AdaBoost', 'n_estimators': 210, 'learning_rate': 1.0009392533067958}. Best is trial 11 with value: 0.8031272210376688.\u001b[0m\n",
      "\u001b[32m[I 2022-09-06 20:24:23,286]\u001b[0m Trial 12 finished with value: 0.7953091684434968 and parameters: {'classifier': 'AdaBoost', 'n_estimators': 200, 'learning_rate': 1.0498808172424945}. Best is trial 11 with value: 0.8031272210376688.\u001b[0m\n",
      "\u001b[32m[I 2022-09-06 20:24:24,074]\u001b[0m Trial 13 finished with value: 0.7995735607675906 and parameters: {'classifier': 'AdaBoost', 'n_estimators': 210, 'learning_rate': 1.0855996088686253}. Best is trial 11 with value: 0.8031272210376688.\u001b[0m\n",
      "\u001b[32m[I 2022-09-06 20:24:24,489]\u001b[0m Trial 14 finished with value: 0.8031272210376688 and parameters: {'classifier': 'AdaBoost', 'n_estimators': 110, 'learning_rate': 0.9790470689499624}. Best is trial 11 with value: 0.8031272210376688.\u001b[0m\n",
      "<timed exec>:20: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "/Users/ivanpua/opt/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "\u001b[32m[I 2022-09-06 20:24:24,555]\u001b[0m Trial 15 finished with value: 0.7910447761194029 and parameters: {'classifier': 'Logistic', 'penalty': 'l2', 'logistic-regularization': 8.915765952098555}. Best is trial 11 with value: 0.8031272210376688.\u001b[0m\n",
      "\u001b[32m[I 2022-09-06 20:24:24,641]\u001b[0m Trial 16 finished with value: 0.7967306325515281 and parameters: {'classifier': 'AdaBoost', 'n_estimators': 20, 'learning_rate': 0.7544396668034471}. Best is trial 11 with value: 0.8031272210376688.\u001b[0m\n",
      "\u001b[32m[I 2022-09-06 20:24:25,058]\u001b[0m Trial 17 finished with value: 0.8059701492537313 and parameters: {'classifier': 'AdaBoost', 'n_estimators': 110, 'learning_rate': 0.24912393665597488}. Best is trial 17 with value: 0.8059701492537313.\u001b[0m\n",
      "<timed exec>:20: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "/Users/ivanpua/opt/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-09-06 20:24:25,163]\u001b[0m Trial 18 finished with value: 0.7398720682302772 and parameters: {'classifier': 'Logistic', 'penalty': 'l1', 'logistic-regularization': 0.06426139184007607}. Best is trial 17 with value: 0.8059701492537313.\u001b[0m\n",
      "\u001b[32m[I 2022-09-06 20:24:25,590]\u001b[0m Trial 19 finished with value: 0.8052594171997157 and parameters: {'classifier': 'AdaBoost', 'n_estimators': 110, 'learning_rate': 0.1272571653839483}. Best is trial 17 with value: 0.8059701492537313.\u001b[0m\n",
      "\u001b[32m[I 2022-09-06 20:24:27,437]\u001b[0m Trial 20 finished with value: 0.7967306325515281 and parameters: {'classifier': 'AdaBoost', 'n_estimators': 500, 'learning_rate': 0.1746076372722989}. Best is trial 17 with value: 0.8059701492537313.\u001b[0m\n",
      "\u001b[32m[I 2022-09-06 20:24:27,856]\u001b[0m Trial 21 finished with value: 0.806680881307747 and parameters: {'classifier': 'AdaBoost', 'n_estimators': 110, 'learning_rate': 0.11616214775289899}. Best is trial 21 with value: 0.806680881307747.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-09-06 20:24:28,280]\u001b[0m Trial 22 finished with value: 0.806680881307747 and parameters: {'classifier': 'AdaBoost', 'n_estimators': 110, 'learning_rate': 0.18839990969001152}. Best is trial 21 with value: 0.806680881307747.\u001b[0m\n",
      "\u001b[32m[I 2022-09-06 20:24:28,326]\u001b[0m Trial 23 finished with value: 0.8137882018479033 and parameters: {'classifier': 'AdaBoost', 'n_estimators': 10, 'learning_rate': 0.555344080589061}. Best is trial 23 with value: 0.8137882018479033.\u001b[0m\n",
      "\u001b[32m[I 2022-09-06 20:24:28,372]\u001b[0m Trial 24 finished with value: 0.8137882018479033 and parameters: {'classifier': 'AdaBoost', 'n_estimators': 10, 'learning_rate': 0.5518318016037921}. Best is trial 23 with value: 0.8137882018479033.\u001b[0m\n",
      "\u001b[32m[I 2022-09-06 20:24:28,455]\u001b[0m Trial 25 finished with value: 0.7974413646055437 and parameters: {'classifier': 'AdaBoost', 'n_estimators': 20, 'learning_rate': 0.6416417273836444}. Best is trial 23 with value: 0.8137882018479033.\u001b[0m\n",
      "<timed exec>:20: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "/Users/ivanpua/opt/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "\u001b[32m[I 2022-09-06 20:24:28,516]\u001b[0m Trial 26 finished with value: 0.798862828713575 and parameters: {'classifier': 'Logistic', 'penalty': 'l2', 'logistic-regularization': 4.254934976456849}. Best is trial 23 with value: 0.8137882018479033.\u001b[0m\n",
      "\u001b[32m[I 2022-09-06 20:24:28,752]\u001b[0m Trial 27 finished with value: 0.8081023454157783 and parameters: {'classifier': 'AdaBoost', 'n_estimators': 60, 'learning_rate': 0.5072171873931866}. Best is trial 23 with value: 0.8137882018479033.\u001b[0m\n",
      "\u001b[32m[I 2022-09-06 20:24:28,799]\u001b[0m Trial 28 finished with value: 0.8137882018479033 and parameters: {'classifier': 'AdaBoost', 'n_estimators': 10, 'learning_rate': 0.542259709179193}. Best is trial 23 with value: 0.8137882018479033.\u001b[0m\n",
      "\u001b[32m[I 2022-09-06 20:24:28,846]\u001b[0m Trial 29 finished with value: 0.7974413646055437 and parameters: {'classifier': 'AdaBoost', 'n_estimators': 10, 'learning_rate': 0.790944796482868}. Best is trial 23 with value: 0.8137882018479033.\u001b[0m\n",
      "\u001b[32m[I 2022-09-06 20:24:29,079]\u001b[0m Trial 30 finished with value: 0.7938877043354655 and parameters: {'classifier': 'AdaBoost', 'n_estimators': 60, 'learning_rate': 1.3855786750829067}. Best is trial 23 with value: 0.8137882018479033.\u001b[0m\n",
      "\u001b[32m[I 2022-09-06 20:24:29,308]\u001b[0m Trial 31 finished with value: 0.8059701492537313 and parameters: {'classifier': 'AdaBoost', 'n_estimators': 60, 'learning_rate': 0.47039717847367296}. Best is trial 23 with value: 0.8137882018479033.\u001b[0m\n",
      "\u001b[32m[I 2022-09-06 20:24:29,501]\u001b[0m Trial 32 finished with value: 0.8052594171997157 and parameters: {'classifier': 'AdaBoost', 'n_estimators': 50, 'learning_rate': 0.5088509088573357}. Best is trial 23 with value: 0.8137882018479033.\u001b[0m\n",
      "\u001b[32m[I 2022-09-06 20:24:29,547]\u001b[0m Trial 33 finished with value: 0.7981520966595593 and parameters: {'classifier': 'AdaBoost', 'n_estimators': 10, 'learning_rate': 0.8063130772053821}. Best is trial 23 with value: 0.8137882018479033.\u001b[0m\n",
      "\u001b[32m[I 2022-09-06 20:24:29,816]\u001b[0m Trial 34 finished with value: 0.7924662402274343 and parameters: {'classifier': 'AdaBoost', 'n_estimators': 70, 'learning_rate': 1.8076225077371175}. Best is trial 23 with value: 0.8137882018479033.\u001b[0m\n",
      "\u001b[32m[I 2022-09-06 20:24:30,420]\u001b[0m Trial 35 finished with value: 0.8009950248756219 and parameters: {'classifier': 'AdaBoost', 'n_estimators': 160, 'learning_rate': 0.40764551273149646}. Best is trial 23 with value: 0.8137882018479033.\u001b[0m\n",
      "\u001b[32m[I 2022-09-06 20:24:30,577]\u001b[0m Trial 36 finished with value: 0.8038379530916845 and parameters: {'classifier': 'AdaBoost', 'n_estimators': 40, 'learning_rate': 0.6842228093575551}. Best is trial 23 with value: 0.8137882018479033.\u001b[0m\n",
      "<timed exec>:20: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "/Users/ivanpua/opt/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-09-06 20:24:30,683]\u001b[0m Trial 37 finished with value: 0.7398720682302772 and parameters: {'classifier': 'Logistic', 'penalty': 'l1', 'logistic-regularization': 6.088516053056587}. Best is trial 23 with value: 0.8137882018479033.\u001b[0m\n",
      "\u001b[32m[I 2022-09-06 20:24:30,995]\u001b[0m Trial 38 finished with value: 0.798862828713575 and parameters: {'classifier': 'AdaBoost', 'n_estimators': 80, 'learning_rate': 1.2081136209866807}. Best is trial 23 with value: 0.8137882018479033.\u001b[0m\n",
      "\u001b[32m[I 2022-09-06 20:24:31,554]\u001b[0m Trial 39 finished with value: 0.8024164889836531 and parameters: {'classifier': 'AdaBoost', 'n_estimators': 150, 'learning_rate': 0.8699536632244362}. Best is trial 23 with value: 0.8137882018479033.\u001b[0m\n",
      "\u001b[32m[I 2022-09-06 20:24:31,589]\u001b[0m Trial 40 finished with value: 0.2601279317697228 and parameters: {'classifier': 'AdaBoost', 'n_estimators': 10, 'learning_rate': 2.9397783560534525}. Best is trial 23 with value: 0.8137882018479033.\u001b[0m\n",
      "\u001b[32m[I 2022-09-06 20:24:31,929]\u001b[0m Trial 41 finished with value: 0.8073916133617626 and parameters: {'classifier': 'AdaBoost', 'n_estimators': 90, 'learning_rate': 0.3450126124103704}. Best is trial 23 with value: 0.8137882018479033.\u001b[0m\n",
      "\u001b[32m[I 2022-09-06 20:24:32,234]\u001b[0m Trial 42 finished with value: 0.8052594171997157 and parameters: {'classifier': 'AdaBoost', 'n_estimators': 80, 'learning_rate': 0.31509389386373193}. Best is trial 23 with value: 0.8137882018479033.\u001b[0m\n",
      "\u001b[32m[I 2022-09-06 20:24:32,390]\u001b[0m Trial 43 finished with value: 0.8059701492537313 and parameters: {'classifier': 'AdaBoost', 'n_estimators': 40, 'learning_rate': 0.5175329818846118}. Best is trial 23 with value: 0.8137882018479033.\u001b[0m\n",
      "\u001b[32m[I 2022-09-06 20:24:32,510]\u001b[0m Trial 44 finished with value: 0.8081023454157783 and parameters: {'classifier': 'AdaBoost', 'n_estimators': 30, 'learning_rate': 0.3874462400727452}. Best is trial 23 with value: 0.8137882018479033.\u001b[0m\n",
      "\u001b[32m[I 2022-09-06 20:24:32,596]\u001b[0m Trial 45 finished with value: 0.26083866382373844 and parameters: {'classifier': 'AdaBoost', 'n_estimators': 30, 'learning_rate': 2.2784664253199534}. Best is trial 23 with value: 0.8137882018479033.\u001b[0m\n",
      "<timed exec>:20: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "/Users/ivanpua/opt/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "\u001b[32m[I 2022-09-06 20:24:32,650]\u001b[0m Trial 46 finished with value: 0.7903340440653873 and parameters: {'classifier': 'Logistic', 'penalty': 'l2', 'logistic-regularization': 2.7136468561587703}. Best is trial 23 with value: 0.8137882018479033.\u001b[0m\n",
      "\u001b[32m[I 2022-09-06 20:24:32,823]\u001b[0m Trial 47 finished with value: 0.7974413646055437 and parameters: {'classifier': 'AdaBoost', 'n_estimators': 40, 'learning_rate': 0.6350918842988785}. Best is trial 23 with value: 0.8137882018479033.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-09-06 20:24:32,873]\u001b[0m Trial 48 finished with value: 0.7739872068230277 and parameters: {'classifier': 'AdaBoost', 'n_estimators': 10, 'learning_rate': 1.5950159801270372}. Best is trial 23 with value: 0.8137882018479033.\u001b[0m\n",
      "\u001b[32m[I 2022-09-06 20:24:34,115]\u001b[0m Trial 49 finished with value: 0.7995735607675906 and parameters: {'classifier': 'AdaBoost', 'n_estimators': 320, 'learning_rate': 0.39890582787312556}. Best is trial 23 with value: 0.8137882018479033.\u001b[0m\n",
      "\u001b[32m[I 2022-09-06 20:24:34,313]\u001b[0m Trial 50 finished with value: 0.8024164889836531 and parameters: {'classifier': 'AdaBoost', 'n_estimators': 50, 'learning_rate': 0.8811385664908157}. Best is trial 23 with value: 0.8137882018479033.\u001b[0m\n",
      "\u001b[32m[I 2022-09-06 20:24:34,624]\u001b[0m Trial 51 finished with value: 0.806680881307747 and parameters: {'classifier': 'AdaBoost', 'n_estimators': 80, 'learning_rate': 0.34382822070239466}. Best is trial 23 with value: 0.8137882018479033.\u001b[0m\n",
      "\u001b[32m[I 2022-09-06 20:24:35,164]\u001b[0m Trial 52 finished with value: 0.8002842928216063 and parameters: {'classifier': 'AdaBoost', 'n_estimators': 140, 'learning_rate': 0.6024275541543935}. Best is trial 23 with value: 0.8137882018479033.\u001b[0m\n",
      "\u001b[32m[I 2022-09-06 20:24:35,524]\u001b[0m Trial 53 finished with value: 0.8045486851457001 and parameters: {'classifier': 'AdaBoost', 'n_estimators': 90, 'learning_rate': 0.29729758998802913}. Best is trial 23 with value: 0.8137882018479033.\u001b[0m\n",
      "\u001b[32m[I 2022-09-06 20:24:35,648]\u001b[0m Trial 54 finished with value: 0.8095238095238095 and parameters: {'classifier': 'AdaBoost', 'n_estimators': 30, 'learning_rate': 0.5058128785483633}. Best is trial 23 with value: 0.8137882018479033.\u001b[0m\n",
      "<timed exec>:20: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "/Users/ivanpua/opt/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-09-06 20:24:35,757]\u001b[0m Trial 55 finished with value: 0.7398720682302772 and parameters: {'classifier': 'Logistic', 'penalty': 'l1', 'logistic-regularization': 9.534208620457141}. Best is trial 23 with value: 0.8137882018479033.\u001b[0m\n",
      "\u001b[32m[I 2022-09-06 20:24:35,881]\u001b[0m Trial 56 finished with value: 0.8102345415778252 and parameters: {'classifier': 'AdaBoost', 'n_estimators': 30, 'learning_rate': 0.5014563545384295}. Best is trial 23 with value: 0.8137882018479033.\u001b[0m\n",
      "\u001b[32m[I 2022-09-06 20:24:36,116]\u001b[0m Trial 57 finished with value: 0.7981520966595593 and parameters: {'classifier': 'AdaBoost', 'n_estimators': 60, 'learning_rate': 0.9438266403606004}. Best is trial 23 with value: 0.8137882018479033.\u001b[0m\n",
      "\u001b[32m[I 2022-09-06 20:24:37,617]\u001b[0m Trial 58 finished with value: 0.7953091684434968 and parameters: {'classifier': 'AdaBoost', 'n_estimators': 400, 'learning_rate': 0.7099247557123634}. Best is trial 23 with value: 0.8137882018479033.\u001b[0m\n",
      "\u001b[32m[I 2022-09-06 20:24:37,747]\u001b[0m Trial 59 finished with value: 0.8002842928216063 and parameters: {'classifier': 'AdaBoost', 'n_estimators': 30, 'learning_rate': 1.1363469947171514}. Best is trial 23 with value: 0.8137882018479033.\u001b[0m\n",
      "\u001b[32m[I 2022-09-06 20:24:38,718]\u001b[0m Trial 60 finished with value: 0.8002842928216063 and parameters: {'classifier': 'AdaBoost', 'n_estimators': 260, 'learning_rate': 0.5770541687964303}. Best is trial 23 with value: 0.8137882018479033.\u001b[0m\n",
      "\u001b[32m[I 2022-09-06 20:24:38,838]\u001b[0m Trial 61 finished with value: 0.8038379530916845 and parameters: {'classifier': 'AdaBoost', 'n_estimators': 30, 'learning_rate': 0.4819566437585694}. Best is trial 23 with value: 0.8137882018479033.\u001b[0m\n",
      "\u001b[32m[I 2022-09-06 20:24:38,883]\u001b[0m Trial 62 finished with value: 0.7874911158493249 and parameters: {'classifier': 'AdaBoost', 'n_estimators': 10, 'learning_rate': 0.25052560063449697}. Best is trial 23 with value: 0.8137882018479033.\u001b[0m\n",
      "\u001b[32m[I 2022-09-06 20:24:39,112]\u001b[0m Trial 63 finished with value: 0.8045486851457001 and parameters: {'classifier': 'AdaBoost', 'n_estimators': 60, 'learning_rate': 0.728022476307058}. Best is trial 23 with value: 0.8137882018479033.\u001b[0m\n",
      "\u001b[32m[I 2022-09-06 20:24:39,235]\u001b[0m Trial 64 finished with value: 0.8045486851457001 and parameters: {'classifier': 'AdaBoost', 'n_estimators': 30, 'learning_rate': 0.4643236843433881}. Best is trial 23 with value: 0.8137882018479033.\u001b[0m\n",
      "\u001b[32m[I 2022-09-06 20:24:39,393]\u001b[0m Trial 65 finished with value: 0.8059701492537313 and parameters: {'classifier': 'AdaBoost', 'n_estimators': 40, 'learning_rate': 0.5849652075300653}. Best is trial 23 with value: 0.8137882018479033.\u001b[0m\n",
      "<timed exec>:20: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "/Users/ivanpua/opt/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "\u001b[32m[I 2022-09-06 20:24:39,440]\u001b[0m Trial 66 finished with value: 0.7938877043354655 and parameters: {'classifier': 'Logistic', 'penalty': 'l2', 'logistic-regularization': 6.543991042090917}. Best is trial 23 with value: 0.8137882018479033.\u001b[0m\n",
      "\u001b[32m[I 2022-09-06 20:24:39,934]\u001b[0m Trial 67 finished with value: 0.806680881307747 and parameters: {'classifier': 'AdaBoost', 'n_estimators': 130, 'learning_rate': 0.2577601928658388}. Best is trial 23 with value: 0.8137882018479033.\u001b[0m\n",
      "\u001b[32m[I 2022-09-06 20:24:40,600]\u001b[0m Trial 68 finished with value: 0.7995735607675906 and parameters: {'classifier': 'AdaBoost', 'n_estimators': 180, 'learning_rate': 0.7756725001868248}. Best is trial 23 with value: 0.8137882018479033.\u001b[0m\n",
      "\u001b[32m[I 2022-09-06 20:24:40,979]\u001b[0m Trial 69 finished with value: 0.8059701492537313 and parameters: {'classifier': 'AdaBoost', 'n_estimators': 100, 'learning_rate': 0.12378413871618477}. Best is trial 23 with value: 0.8137882018479033.\u001b[0m\n",
      "\u001b[32m[I 2022-09-06 20:24:41,061]\u001b[0m Trial 70 finished with value: 0.8059701492537313 and parameters: {'classifier': 'AdaBoost', 'n_estimators': 20, 'learning_rate': 0.4344880668242938}. Best is trial 23 with value: 0.8137882018479033.\u001b[0m\n",
      "\u001b[32m[I 2022-09-06 20:24:41,330]\u001b[0m Trial 71 finished with value: 0.8045486851457001 and parameters: {'classifier': 'AdaBoost', 'n_estimators': 70, 'learning_rate': 0.36672425073957626}. Best is trial 23 with value: 0.8137882018479033.\u001b[0m\n",
      "\u001b[32m[I 2022-09-06 20:24:41,522]\u001b[0m Trial 72 finished with value: 0.8045486851457001 and parameters: {'classifier': 'AdaBoost', 'n_estimators': 50, 'learning_rate': 0.5453497109099074}. Best is trial 23 with value: 0.8137882018479033.\u001b[0m\n",
      "\u001b[32m[I 2022-09-06 20:24:41,866]\u001b[0m Trial 73 finished with value: 0.806680881307747 and parameters: {'classifier': 'AdaBoost', 'n_estimators': 90, 'learning_rate': 0.1917866790479465}. Best is trial 23 with value: 0.8137882018479033.\u001b[0m\n",
      "\u001b[32m[I 2022-09-06 20:24:41,949]\u001b[0m Trial 74 finished with value: 0.8045486851457001 and parameters: {'classifier': 'AdaBoost', 'n_estimators': 20, 'learning_rate': 0.6772435601109144}. Best is trial 23 with value: 0.8137882018479033.\u001b[0m\n",
      "\u001b[32m[I 2022-09-06 20:24:42,216]\u001b[0m Trial 75 finished with value: 0.8038379530916845 and parameters: {'classifier': 'AdaBoost', 'n_estimators': 70, 'learning_rate': 0.39120316244459685}. Best is trial 23 with value: 0.8137882018479033.\u001b[0m\n",
      "\u001b[32m[I 2022-09-06 20:24:42,409]\u001b[0m Trial 76 finished with value: 0.8059701492537313 and parameters: {'classifier': 'AdaBoost', 'n_estimators': 50, 'learning_rate': 0.8953495697002462}. Best is trial 23 with value: 0.8137882018479033.\u001b[0m\n",
      "<timed exec>:20: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-09-06 20:24:42,453]\u001b[0m Trial 77 finished with value: 0.7903340440653873 and parameters: {'classifier': 'Logistic', 'penalty': 'l2', 'logistic-regularization': 2.4337697273176335}. Best is trial 23 with value: 0.8137882018479033.\u001b[0m\n",
      "\u001b[32m[I 2022-09-06 20:24:42,500]\u001b[0m Trial 78 finished with value: 0.8052594171997157 and parameters: {'classifier': 'AdaBoost', 'n_estimators': 10, 'learning_rate': 0.5056083613266483}. Best is trial 23 with value: 0.8137882018479033.\u001b[0m\n",
      "\u001b[32m[I 2022-09-06 20:24:42,955]\u001b[0m Trial 79 finished with value: 0.8059701492537313 and parameters: {'classifier': 'AdaBoost', 'n_estimators': 120, 'learning_rate': 0.20999445073531886}. Best is trial 23 with value: 0.8137882018479033.\u001b[0m\n",
      "\u001b[32m[I 2022-09-06 20:24:44,780]\u001b[0m Trial 80 finished with value: 0.7981520966595593 and parameters: {'classifier': 'AdaBoost', 'n_estimators': 490, 'learning_rate': 0.6363931733956808}. Best is trial 23 with value: 0.8137882018479033.\u001b[0m\n",
      "\u001b[32m[I 2022-09-06 20:24:44,901]\u001b[0m Trial 81 finished with value: 0.8073916133617626 and parameters: {'classifier': 'AdaBoost', 'n_estimators': 30, 'learning_rate': 0.3481457097492666}. Best is trial 23 with value: 0.8137882018479033.\u001b[0m\n",
      "\u001b[32m[I 2022-09-06 20:24:45,021]\u001b[0m Trial 82 finished with value: 0.8052594171997157 and parameters: {'classifier': 'AdaBoost', 'n_estimators': 30, 'learning_rate': 0.32799093562466536}. Best is trial 23 with value: 0.8137882018479033.\u001b[0m\n",
      "\u001b[32m[I 2022-09-06 20:24:45,216]\u001b[0m Trial 83 finished with value: 0.7398720682302772 and parameters: {'classifier': 'AdaBoost', 'n_estimators': 50, 'learning_rate': 1.9941195610081819}. Best is trial 23 with value: 0.8137882018479033.\u001b[0m\n",
      "\u001b[32m[I 2022-09-06 20:24:46,113]\u001b[0m Trial 84 finished with value: 0.8024164889836531 and parameters: {'classifier': 'AdaBoost', 'n_estimators': 240, 'learning_rate': 0.4460937345572018}. Best is trial 23 with value: 0.8137882018479033.\u001b[0m\n",
      "\u001b[32m[I 2022-09-06 20:24:46,232]\u001b[0m Trial 85 finished with value: 0.8009950248756219 and parameters: {'classifier': 'AdaBoost', 'n_estimators': 30, 'learning_rate': 0.7952376389812826}. Best is trial 23 with value: 0.8137882018479033.\u001b[0m\n",
      "\u001b[32m[I 2022-09-06 20:24:46,278]\u001b[0m Trial 86 finished with value: 0.8137882018479033 and parameters: {'classifier': 'AdaBoost', 'n_estimators': 10, 'learning_rate': 0.5688796886446723}. Best is trial 23 with value: 0.8137882018479033.\u001b[0m\n",
      "\u001b[32m[I 2022-09-06 20:24:46,323]\u001b[0m Trial 87 finished with value: 0.7896233120113717 and parameters: {'classifier': 'AdaBoost', 'n_estimators': 10, 'learning_rate': 1.0206214673035094}. Best is trial 23 with value: 0.8137882018479033.\u001b[0m\n",
      "\u001b[32m[I 2022-09-06 20:24:46,552]\u001b[0m Trial 88 finished with value: 0.806680881307747 and parameters: {'classifier': 'AdaBoost', 'n_estimators': 60, 'learning_rate': 0.5323703168245713}. Best is trial 23 with value: 0.8137882018479033.\u001b[0m\n",
      "\u001b[32m[I 2022-09-06 20:24:46,635]\u001b[0m Trial 89 finished with value: 0.7810945273631841 and parameters: {'classifier': 'AdaBoost', 'n_estimators': 20, 'learning_rate': 0.10148459486008249}. Best is trial 23 with value: 0.8137882018479033.\u001b[0m\n",
      "<timed exec>:20: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "/Users/ivanpua/opt/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-09-06 20:24:46,739]\u001b[0m Trial 90 finished with value: 0.7398720682302772 and parameters: {'classifier': 'Logistic', 'penalty': 'l1', 'logistic-regularization': 2.2803976194101145}. Best is trial 23 with value: 0.8137882018479033.\u001b[0m\n",
      "\u001b[32m[I 2022-09-06 20:24:46,901]\u001b[0m Trial 91 finished with value: 0.8081023454157783 and parameters: {'classifier': 'AdaBoost', 'n_estimators': 40, 'learning_rate': 0.3764497613528697}. Best is trial 23 with value: 0.8137882018479033.\u001b[0m\n",
      "\u001b[32m[I 2022-09-06 20:24:47,060]\u001b[0m Trial 92 finished with value: 0.8045486851457001 and parameters: {'classifier': 'AdaBoost', 'n_estimators': 40, 'learning_rate': 0.5899747250861496}. Best is trial 23 with value: 0.8137882018479033.\u001b[0m\n",
      "\u001b[32m[I 2022-09-06 20:24:47,106]\u001b[0m Trial 93 finished with value: 0.8024164889836531 and parameters: {'classifier': 'AdaBoost', 'n_estimators': 10, 'learning_rate': 0.41713391276543693}. Best is trial 23 with value: 0.8137882018479033.\u001b[0m\n",
      "\u001b[32m[I 2022-09-06 20:24:47,376]\u001b[0m Trial 94 finished with value: 0.8059701492537313 and parameters: {'classifier': 'AdaBoost', 'n_estimators': 70, 'learning_rate': 0.2813942147916205}. Best is trial 23 with value: 0.8137882018479033.\u001b[0m\n",
      "\u001b[32m[I 2022-09-06 20:24:47,532]\u001b[0m Trial 95 finished with value: 0.806680881307747 and parameters: {'classifier': 'AdaBoost', 'n_estimators': 40, 'learning_rate': 0.6720744527953202}. Best is trial 23 with value: 0.8137882018479033.\u001b[0m\n",
      "\u001b[32m[I 2022-09-06 20:24:47,617]\u001b[0m Trial 96 finished with value: 0.8073916133617626 and parameters: {'classifier': 'AdaBoost', 'n_estimators': 20, 'learning_rate': 0.4892536201278611}. Best is trial 23 with value: 0.8137882018479033.\u001b[0m\n",
      "\u001b[32m[I 2022-09-06 20:24:47,664]\u001b[0m Trial 97 finished with value: 0.8052594171997157 and parameters: {'classifier': 'AdaBoost', 'n_estimators': 10, 'learning_rate': 0.5217366425241483}. Best is trial 23 with value: 0.8137882018479033.\u001b[0m\n",
      "\u001b[32m[I 2022-09-06 20:24:48,002]\u001b[0m Trial 98 finished with value: 0.8045486851457001 and parameters: {'classifier': 'AdaBoost', 'n_estimators': 90, 'learning_rate': 0.7273644288869805}. Best is trial 23 with value: 0.8137882018479033.\u001b[0m\n",
      "\u001b[32m[I 2022-09-06 20:24:48,059]\u001b[0m Trial 99 finished with value: 0.2601279317697228 and parameters: {'classifier': 'AdaBoost', 'n_estimators': 20, 'learning_rate': 2.454758671452139}. Best is trial 23 with value: 0.8137882018479033.\u001b[0m\n",
      "\u001b[32m[I 2022-09-06 20:24:48,253]\u001b[0m Trial 100 finished with value: 0.8024164889836531 and parameters: {'classifier': 'AdaBoost', 'n_estimators': 50, 'learning_rate': 0.6260562050169254}. Best is trial 23 with value: 0.8137882018479033.\u001b[0m\n",
      "\u001b[32m[I 2022-09-06 20:24:48,409]\u001b[0m Trial 101 finished with value: 0.806680881307747 and parameters: {'classifier': 'AdaBoost', 'n_estimators': 40, 'learning_rate': 0.4717144807035254}. Best is trial 23 with value: 0.8137882018479033.\u001b[0m\n",
      "\u001b[32m[I 2022-09-06 20:24:48,492]\u001b[0m Trial 102 finished with value: 0.8073916133617626 and parameters: {'classifier': 'AdaBoost', 'n_estimators': 20, 'learning_rate': 0.39621746699200827}. Best is trial 23 with value: 0.8137882018479033.\u001b[0m\n",
      "\u001b[32m[I 2022-09-06 20:24:48,722]\u001b[0m Trial 103 finished with value: 0.8052594171997157 and parameters: {'classifier': 'AdaBoost', 'n_estimators': 60, 'learning_rate': 0.3794879178351416}. Best is trial 23 with value: 0.8137882018479033.\u001b[0m\n",
      "\u001b[32m[I 2022-09-06 20:24:48,849]\u001b[0m Trial 104 finished with value: 0.8017057569296375 and parameters: {'classifier': 'AdaBoost', 'n_estimators': 30, 'learning_rate': 0.23231741846905934}. Best is trial 23 with value: 0.8137882018479033.\u001b[0m\n",
      "\u001b[32m[I 2022-09-06 20:24:49,156]\u001b[0m Trial 105 finished with value: 0.806680881307747 and parameters: {'classifier': 'AdaBoost', 'n_estimators': 80, 'learning_rate': 0.31708735744594574}. Best is trial 23 with value: 0.8137882018479033.\u001b[0m\n",
      "\u001b[32m[I 2022-09-06 20:24:49,277]\u001b[0m Trial 106 finished with value: 0.8073916133617626 and parameters: {'classifier': 'AdaBoost', 'n_estimators': 30, 'learning_rate': 0.5658061663453675}. Best is trial 23 with value: 0.8137882018479033.\u001b[0m\n",
      "\u001b[32m[I 2022-09-06 20:24:50,687]\u001b[0m Trial 107 finished with value: 0.7981520966595593 and parameters: {'classifier': 'AdaBoost', 'n_estimators': 380, 'learning_rate': 0.8294853190727096}. Best is trial 23 with value: 0.8137882018479033.\u001b[0m\n",
      "<timed exec>:20: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "/Users/ivanpua/opt/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-09-06 20:24:50,791]\u001b[0m Trial 108 finished with value: 0.7398720682302772 and parameters: {'classifier': 'Logistic', 'penalty': 'l1', 'logistic-regularization': 7.971392118170745}. Best is trial 23 with value: 0.8137882018479033.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-09-06 20:24:50,876]\u001b[0m Trial 109 finished with value: 0.8059701492537313 and parameters: {'classifier': 'AdaBoost', 'n_estimators': 20, 'learning_rate': 0.44101928726051476}. Best is trial 23 with value: 0.8137882018479033.\u001b[0m\n",
      "\u001b[32m[I 2022-09-06 20:24:51,038]\u001b[0m Trial 110 finished with value: 0.8009950248756219 and parameters: {'classifier': 'AdaBoost', 'n_estimators': 40, 'learning_rate': 0.16470916247413295}. Best is trial 23 with value: 0.8137882018479033.\u001b[0m\n",
      "\u001b[32m[I 2022-09-06 20:24:51,160]\u001b[0m Trial 111 finished with value: 0.8073916133617626 and parameters: {'classifier': 'AdaBoost', 'n_estimators': 30, 'learning_rate': 0.5644761482016566}. Best is trial 23 with value: 0.8137882018479033.\u001b[0m\n",
      "\u001b[32m[I 2022-09-06 20:24:51,426]\u001b[0m Trial 112 finished with value: 0.8045486851457001 and parameters: {'classifier': 'AdaBoost', 'n_estimators': 70, 'learning_rate': 0.34733539259857593}. Best is trial 23 with value: 0.8137882018479033.\u001b[0m\n",
      "\u001b[32m[I 2022-09-06 20:24:51,472]\u001b[0m Trial 113 finished with value: 0.8137882018479033 and parameters: {'classifier': 'AdaBoost', 'n_estimators': 10, 'learning_rate': 0.5544203954544097}. Best is trial 23 with value: 0.8137882018479033.\u001b[0m\n",
      "\u001b[32m[I 2022-09-06 20:24:51,518]\u001b[0m Trial 114 finished with value: 0.7896233120113717 and parameters: {'classifier': 'AdaBoost', 'n_estimators': 10, 'learning_rate': 1.3272436900204791}. Best is trial 23 with value: 0.8137882018479033.\u001b[0m\n",
      "\u001b[32m[I 2022-09-06 20:24:51,721]\u001b[0m Trial 115 finished with value: 0.8045486851457001 and parameters: {'classifier': 'AdaBoost', 'n_estimators': 50, 'learning_rate': 0.6860518411431062}. Best is trial 23 with value: 0.8137882018479033.\u001b[0m\n",
      "\u001b[32m[I 2022-09-06 20:24:51,804]\u001b[0m Trial 116 finished with value: 0.8059701492537313 and parameters: {'classifier': 'AdaBoost', 'n_estimators': 20, 'learning_rate': 0.4848092792775547}. Best is trial 23 with value: 0.8137882018479033.\u001b[0m\n",
      "\u001b[32m[I 2022-09-06 20:24:52,034]\u001b[0m Trial 117 finished with value: 0.8031272210376688 and parameters: {'classifier': 'AdaBoost', 'n_estimators': 60, 'learning_rate': 0.5573426504613458}. Best is trial 23 with value: 0.8137882018479033.\u001b[0m\n",
      "\u001b[32m[I 2022-09-06 20:24:52,080]\u001b[0m Trial 118 finished with value: 0.8017057569296375 and parameters: {'classifier': 'AdaBoost', 'n_estimators': 10, 'learning_rate': 0.6274974496637655}. Best is trial 23 with value: 0.8137882018479033.\u001b[0m\n",
      "\u001b[32m[I 2022-09-06 20:24:52,274]\u001b[0m Trial 119 finished with value: 0.8024164889836531 and parameters: {'classifier': 'AdaBoost', 'n_estimators': 50, 'learning_rate': 0.7578339245737029}. Best is trial 23 with value: 0.8137882018479033.\u001b[0m\n",
      "\u001b[32m[I 2022-09-06 20:24:52,395]\u001b[0m Trial 120 finished with value: 0.8024164889836531 and parameters: {'classifier': 'AdaBoost', 'n_estimators': 30, 'learning_rate': 0.28784717125169157}. Best is trial 23 with value: 0.8137882018479033.\u001b[0m\n",
      "\u001b[32m[I 2022-09-06 20:24:52,556]\u001b[0m Trial 121 finished with value: 0.8088130774697939 and parameters: {'classifier': 'AdaBoost', 'n_estimators': 40, 'learning_rate': 0.4174168492200589}. Best is trial 23 with value: 0.8137882018479033.\u001b[0m\n",
      "\u001b[32m[I 2022-09-06 20:24:52,646]\u001b[0m Trial 122 finished with value: 0.8095238095238095 and parameters: {'classifier': 'AdaBoost', 'n_estimators': 20, 'learning_rate': 0.4312425610214118}. Best is trial 23 with value: 0.8137882018479033.\u001b[0m\n",
      "\u001b[32m[I 2022-09-06 20:24:52,730]\u001b[0m Trial 123 finished with value: 0.8059701492537313 and parameters: {'classifier': 'AdaBoost', 'n_estimators': 20, 'learning_rate': 0.39951943511706844}. Best is trial 23 with value: 0.8137882018479033.\u001b[0m\n",
      "\u001b[32m[I 2022-09-06 20:24:52,890]\u001b[0m Trial 124 finished with value: 0.8073916133617626 and parameters: {'classifier': 'AdaBoost', 'n_estimators': 40, 'learning_rate': 0.4371378646056897}. Best is trial 23 with value: 0.8137882018479033.\u001b[0m\n",
      "\u001b[32m[I 2022-09-06 20:24:53,084]\u001b[0m Trial 125 finished with value: 0.8088130774697939 and parameters: {'classifier': 'AdaBoost', 'n_estimators': 50, 'learning_rate': 0.5264374122349896}. Best is trial 23 with value: 0.8137882018479033.\u001b[0m\n",
      "\u001b[32m[I 2022-09-06 20:24:53,240]\u001b[0m Trial 126 finished with value: 0.8073916133617626 and parameters: {'classifier': 'AdaBoost', 'n_estimators': 40, 'learning_rate': 0.6154994745779073}. Best is trial 23 with value: 0.8137882018479033.\u001b[0m\n",
      "\u001b[32m[I 2022-09-06 20:24:53,286]\u001b[0m Trial 127 finished with value: 0.7882018479033405 and parameters: {'classifier': 'AdaBoost', 'n_estimators': 10, 'learning_rate': 1.6511226324632828}. Best is trial 23 with value: 0.8137882018479033.\u001b[0m\n",
      "\u001b[32m[I 2022-09-06 20:24:53,515]\u001b[0m Trial 128 finished with value: 0.7981520966595593 and parameters: {'classifier': 'AdaBoost', 'n_estimators': 60, 'learning_rate': 1.4817009784010269}. Best is trial 23 with value: 0.8137882018479033.\u001b[0m\n",
      "<timed exec>:20: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "/Users/ivanpua/opt/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "\u001b[32m[I 2022-09-06 20:24:53,558]\u001b[0m Trial 129 finished with value: 0.7882018479033405 and parameters: {'classifier': 'Logistic', 'penalty': 'l2', 'logistic-regularization': 5.532682137010276}. Best is trial 23 with value: 0.8137882018479033.\u001b[0m\n",
      "\u001b[32m[I 2022-09-06 20:24:53,756]\u001b[0m Trial 130 finished with value: 0.806680881307747 and parameters: {'classifier': 'AdaBoost', 'n_estimators': 50, 'learning_rate': 0.5176264842208436}. Best is trial 23 with value: 0.8137882018479033.\u001b[0m\n",
      "\u001b[32m[I 2022-09-06 20:24:54,839]\u001b[0m Trial 131 finished with value: 0.7995735607675906 and parameters: {'classifier': 'AdaBoost', 'n_estimators': 290, 'learning_rate': 0.33422365544143107}. Best is trial 23 with value: 0.8137882018479033.\u001b[0m\n",
      "\u001b[32m[I 2022-09-06 20:24:54,923]\u001b[0m Trial 132 finished with value: 0.8102345415778252 and parameters: {'classifier': 'AdaBoost', 'n_estimators': 20, 'learning_rate': 0.47381865832086384}. Best is trial 23 with value: 0.8137882018479033.\u001b[0m\n",
      "\u001b[32m[I 2022-09-06 20:24:54,972]\u001b[0m Trial 133 finished with value: 0.8017057569296375 and parameters: {'classifier': 'AdaBoost', 'n_estimators': 10, 'learning_rate': 0.4859582832199877}. Best is trial 23 with value: 0.8137882018479033.\u001b[0m\n",
      "\u001b[32m[I 2022-09-06 20:24:55,101]\u001b[0m Trial 134 finished with value: 0.8009950248756219 and parameters: {'classifier': 'AdaBoost', 'n_estimators': 30, 'learning_rate': 0.6748293720799544}. Best is trial 23 with value: 0.8137882018479033.\u001b[0m\n",
      "\u001b[32m[I 2022-09-06 20:24:55,269]\u001b[0m Trial 135 finished with value: 0.8102345415778252 and parameters: {'classifier': 'AdaBoost', 'n_estimators': 40, 'learning_rate': 0.5350260398790249}. Best is trial 23 with value: 0.8137882018479033.\u001b[0m\n",
      "\u001b[32m[I 2022-09-06 20:24:55,360]\u001b[0m Trial 136 finished with value: 0.8102345415778252 and parameters: {'classifier': 'AdaBoost', 'n_estimators': 20, 'learning_rate': 0.5346208640740194}. Best is trial 23 with value: 0.8137882018479033.\u001b[0m\n",
      "\u001b[32m[I 2022-09-06 20:24:55,411]\u001b[0m Trial 137 finished with value: 0.8137882018479033 and parameters: {'classifier': 'AdaBoost', 'n_estimators': 10, 'learning_rate': 0.5685988950875132}. Best is trial 23 with value: 0.8137882018479033.\u001b[0m\n",
      "\u001b[32m[I 2022-09-06 20:24:55,501]\u001b[0m Trial 138 finished with value: 0.7967306325515281 and parameters: {'classifier': 'AdaBoost', 'n_estimators': 20, 'learning_rate': 0.5746597809057675}. Best is trial 23 with value: 0.8137882018479033.\u001b[0m\n",
      "\u001b[32m[I 2022-09-06 20:24:55,553]\u001b[0m Trial 139 finished with value: 0.8137882018479033 and parameters: {'classifier': 'AdaBoost', 'n_estimators': 10, 'learning_rate': 0.5821970581443807}. Best is trial 23 with value: 0.8137882018479033.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-09-06 20:24:55,603]\u001b[0m Trial 140 finished with value: 0.7945984363894811 and parameters: {'classifier': 'AdaBoost', 'n_estimators': 10, 'learning_rate': 0.7100757857705924}. Best is trial 23 with value: 0.8137882018479033.\u001b[0m\n",
      "\u001b[32m[I 2022-09-06 20:24:55,653]\u001b[0m Trial 141 finished with value: 0.8017057569296375 and parameters: {'classifier': 'AdaBoost', 'n_estimators': 10, 'learning_rate': 0.6366340980881569}. Best is trial 23 with value: 0.8137882018479033.\u001b[0m\n",
      "\u001b[32m[I 2022-09-06 20:24:55,741]\u001b[0m Trial 142 finished with value: 0.8059701492537313 and parameters: {'classifier': 'AdaBoost', 'n_estimators': 20, 'learning_rate': 0.5330743800814837}. Best is trial 23 with value: 0.8137882018479033.\u001b[0m\n",
      "\u001b[32m[I 2022-09-06 20:24:55,870]\u001b[0m Trial 143 finished with value: 0.8052594171997157 and parameters: {'classifier': 'AdaBoost', 'n_estimators': 30, 'learning_rate': 0.43379237528741166}. Best is trial 23 with value: 0.8137882018479033.\u001b[0m\n",
      "\u001b[32m[I 2022-09-06 20:24:55,962]\u001b[0m Trial 144 finished with value: 0.7981520966595593 and parameters: {'classifier': 'AdaBoost', 'n_estimators': 20, 'learning_rate': 0.8437201354951296}. Best is trial 23 with value: 0.8137882018479033.\u001b[0m\n",
      "\u001b[32m[I 2022-09-06 20:24:56,132]\u001b[0m Trial 145 finished with value: 0.8052594171997157 and parameters: {'classifier': 'AdaBoost', 'n_estimators': 40, 'learning_rate': 0.6032003421100861}. Best is trial 23 with value: 0.8137882018479033.\u001b[0m\n",
      "\u001b[32m[I 2022-09-06 20:24:56,218]\u001b[0m Trial 146 finished with value: 0.7931769722814499 and parameters: {'classifier': 'AdaBoost', 'n_estimators': 20, 'learning_rate': 0.7361463373500832}. Best is trial 23 with value: 0.8137882018479033.\u001b[0m\n",
      "\u001b[32m[I 2022-09-06 20:24:56,266]\u001b[0m Trial 147 finished with value: 0.8017057569296375 and parameters: {'classifier': 'AdaBoost', 'n_estimators': 10, 'learning_rate': 0.4848436087129019}. Best is trial 23 with value: 0.8137882018479033.\u001b[0m\n",
      "\u001b[32m[I 2022-09-06 20:24:56,389]\u001b[0m Trial 148 finished with value: 0.7995735607675906 and parameters: {'classifier': 'AdaBoost', 'n_estimators': 30, 'learning_rate': 0.9268924376298096}. Best is trial 23 with value: 0.8137882018479033.\u001b[0m\n",
      "\u001b[32m[I 2022-09-06 20:24:56,485]\u001b[0m Trial 149 finished with value: 0.2601279317697228 and parameters: {'classifier': 'AdaBoost', 'n_estimators': 50, 'learning_rate': 2.8087613596158985}. Best is trial 23 with value: 0.8137882018479033.\u001b[0m\n",
      "\u001b[32m[I 2022-09-06 20:24:56,646]\u001b[0m Trial 150 finished with value: 0.8073916133617626 and parameters: {'classifier': 'AdaBoost', 'n_estimators': 40, 'learning_rate': 0.5525917042192934}. Best is trial 23 with value: 0.8137882018479033.\u001b[0m\n",
      "\u001b[32m[I 2022-09-06 20:24:56,768]\u001b[0m Trial 151 finished with value: 0.8052594171997157 and parameters: {'classifier': 'AdaBoost', 'n_estimators': 30, 'learning_rate': 0.4249968112706811}. Best is trial 23 with value: 0.8137882018479033.\u001b[0m\n",
      "\u001b[32m[I 2022-09-06 20:24:56,815]\u001b[0m Trial 152 finished with value: 0.8052594171997157 and parameters: {'classifier': 'AdaBoost', 'n_estimators': 10, 'learning_rate': 0.5197535884992652}. Best is trial 23 with value: 0.8137882018479033.\u001b[0m\n",
      "\u001b[32m[I 2022-09-06 20:24:56,900]\u001b[0m Trial 153 finished with value: 0.8059701492537313 and parameters: {'classifier': 'AdaBoost', 'n_estimators': 20, 'learning_rate': 0.6784018468078755}. Best is trial 23 with value: 0.8137882018479033.\u001b[0m\n",
      "\u001b[32m[I 2022-09-06 20:24:58,779]\u001b[0m Trial 154 finished with value: 0.7953091684434968 and parameters: {'classifier': 'AdaBoost', 'n_estimators': 460, 'learning_rate': 0.5890698660720577}. Best is trial 23 with value: 0.8137882018479033.\u001b[0m\n",
      "\u001b[32m[I 2022-09-06 20:24:59,427]\u001b[0m Trial 155 finished with value: 0.8073916133617626 and parameters: {'classifier': 'AdaBoost', 'n_estimators': 170, 'learning_rate': 0.4786488273994483}. Best is trial 23 with value: 0.8137882018479033.\u001b[0m\n",
      "\u001b[32m[I 2022-09-06 20:24:59,584]\u001b[0m Trial 156 finished with value: 0.8088130774697939 and parameters: {'classifier': 'AdaBoost', 'n_estimators': 40, 'learning_rate': 0.37965932175463446}. Best is trial 23 with value: 0.8137882018479033.\u001b[0m\n",
      "<timed exec>:20: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "\u001b[32m[I 2022-09-06 20:24:59,608]\u001b[0m Trial 157 finished with value: 0.7931769722814499 and parameters: {'classifier': 'Logistic', 'penalty': 'l2', 'logistic-regularization': 9.989836841647758}. Best is trial 23 with value: 0.8137882018479033.\u001b[0m\n",
      "\u001b[32m[I 2022-09-06 20:24:59,769]\u001b[0m Trial 158 finished with value: 0.7953091684434968 and parameters: {'classifier': 'AdaBoost', 'n_estimators': 40, 'learning_rate': 0.6381444123637874}. Best is trial 23 with value: 0.8137882018479033.\u001b[0m\n",
      "\u001b[32m[I 2022-09-06 20:25:00,517]\u001b[0m Trial 159 finished with value: 0.8031272210376688 and parameters: {'classifier': 'AdaBoost', 'n_estimators': 200, 'learning_rate': 0.25166259805552654}. Best is trial 23 with value: 0.8137882018479033.\u001b[0m\n",
      "\u001b[32m[I 2022-09-06 20:25:00,571]\u001b[0m Trial 160 finished with value: 0.8045486851457001 and parameters: {'classifier': 'AdaBoost', 'n_estimators': 10, 'learning_rate': 0.45578972818205954}. Best is trial 23 with value: 0.8137882018479033.\u001b[0m\n",
      "\u001b[32m[I 2022-09-06 20:25:00,704]\u001b[0m Trial 161 finished with value: 0.8095238095238095 and parameters: {'classifier': 'AdaBoost', 'n_estimators': 30, 'learning_rate': 0.37245420734324997}. Best is trial 23 with value: 0.8137882018479033.\u001b[0m\n",
      "\u001b[32m[I 2022-09-06 20:25:00,830]\u001b[0m Trial 162 finished with value: 0.8073916133617626 and parameters: {'classifier': 'AdaBoost', 'n_estimators': 30, 'learning_rate': 0.2910817276284817}. Best is trial 23 with value: 0.8137882018479033.\u001b[0m\n",
      "\u001b[32m[I 2022-09-06 20:25:01,031]\u001b[0m Trial 163 finished with value: 0.806680881307747 and parameters: {'classifier': 'AdaBoost', 'n_estimators': 50, 'learning_rate': 0.3858231664472872}. Best is trial 23 with value: 0.8137882018479033.\u001b[0m\n",
      "\u001b[32m[I 2022-09-06 20:25:01,119]\u001b[0m Trial 164 finished with value: 0.8095238095238095 and parameters: {'classifier': 'AdaBoost', 'n_estimators': 20, 'learning_rate': 0.5388465482505947}. Best is trial 23 with value: 0.8137882018479033.\u001b[0m\n",
      "\u001b[32m[I 2022-09-06 20:25:01,206]\u001b[0m Trial 165 finished with value: 0.8059701492537313 and parameters: {'classifier': 'AdaBoost', 'n_estimators': 20, 'learning_rate': 0.4393359243270551}. Best is trial 23 with value: 0.8137882018479033.\u001b[0m\n",
      "\u001b[32m[I 2022-09-06 20:25:01,254]\u001b[0m Trial 166 finished with value: 0.8137882018479033 and parameters: {'classifier': 'AdaBoost', 'n_estimators': 10, 'learning_rate': 0.5315760165676371}. Best is trial 23 with value: 0.8137882018479033.\u001b[0m\n",
      "\u001b[32m[I 2022-09-06 20:25:01,301]\u001b[0m Trial 167 finished with value: 0.8137882018479033 and parameters: {'classifier': 'AdaBoost', 'n_estimators': 10, 'learning_rate': 0.5906762581893041}. Best is trial 23 with value: 0.8137882018479033.\u001b[0m\n",
      "\u001b[32m[I 2022-09-06 20:25:01,347]\u001b[0m Trial 168 finished with value: 0.8137882018479033 and parameters: {'classifier': 'AdaBoost', 'n_estimators': 10, 'learning_rate': 0.5833864041346472}. Best is trial 23 with value: 0.8137882018479033.\u001b[0m\n",
      "\u001b[32m[I 2022-09-06 20:25:01,394]\u001b[0m Trial 169 finished with value: 0.8137882018479033 and parameters: {'classifier': 'AdaBoost', 'n_estimators': 10, 'learning_rate': 0.5900915401464597}. Best is trial 23 with value: 0.8137882018479033.\u001b[0m\n",
      "\u001b[32m[I 2022-09-06 20:25:01,441]\u001b[0m Trial 170 finished with value: 0.7846481876332623 and parameters: {'classifier': 'AdaBoost', 'n_estimators': 10, 'learning_rate': 0.7838991318473725}. Best is trial 23 with value: 0.8137882018479033.\u001b[0m\n",
      "\u001b[32m[I 2022-09-06 20:25:01,494]\u001b[0m Trial 171 finished with value: 0.8137882018479033 and parameters: {'classifier': 'AdaBoost', 'n_estimators': 10, 'learning_rate': 0.5870295687687507}. Best is trial 23 with value: 0.8137882018479033.\u001b[0m\n",
      "\u001b[32m[I 2022-09-06 20:25:01,549]\u001b[0m Trial 172 finished with value: 0.8088130774697939 and parameters: {'classifier': 'AdaBoost', 'n_estimators': 10, 'learning_rate': 0.6146143685256449}. Best is trial 23 with value: 0.8137882018479033.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-09-06 20:25:01,602]\u001b[0m Trial 173 finished with value: 0.7945984363894811 and parameters: {'classifier': 'AdaBoost', 'n_estimators': 10, 'learning_rate': 0.6719038855753406}. Best is trial 23 with value: 0.8137882018479033.\u001b[0m\n",
      "\u001b[32m[I 2022-09-06 20:25:01,654]\u001b[0m Trial 174 finished with value: 0.8095238095238095 and parameters: {'classifier': 'AdaBoost', 'n_estimators': 10, 'learning_rate': 0.6044886019302786}. Best is trial 23 with value: 0.8137882018479033.\u001b[0m\n",
      "\u001b[32m[I 2022-09-06 20:25:01,743]\u001b[0m Trial 175 finished with value: 0.8024164889836531 and parameters: {'classifier': 'AdaBoost', 'n_estimators': 20, 'learning_rate': 0.7235054183179682}. Best is trial 23 with value: 0.8137882018479033.\u001b[0m\n",
      "\u001b[32m[I 2022-09-06 20:25:01,792]\u001b[0m Trial 176 finished with value: 0.8137882018479033 and parameters: {'classifier': 'AdaBoost', 'n_estimators': 10, 'learning_rate': 0.5896560165280798}. Best is trial 23 with value: 0.8137882018479033.\u001b[0m\n",
      "\u001b[32m[I 2022-09-06 20:25:01,842]\u001b[0m Trial 177 finished with value: 0.8095238095238095 and parameters: {'classifier': 'AdaBoost', 'n_estimators': 10, 'learning_rate': 0.6043066228163539}. Best is trial 23 with value: 0.8137882018479033.\u001b[0m\n",
      "\u001b[32m[I 2022-09-06 20:25:01,937]\u001b[0m Trial 178 finished with value: 0.806680881307747 and parameters: {'classifier': 'AdaBoost', 'n_estimators': 20, 'learning_rate': 0.528838051419418}. Best is trial 23 with value: 0.8137882018479033.\u001b[0m\n",
      "\u001b[32m[I 2022-09-06 20:25:01,986]\u001b[0m Trial 179 finished with value: 0.7945984363894811 and parameters: {'classifier': 'AdaBoost', 'n_estimators': 10, 'learning_rate': 0.667372441917636}. Best is trial 23 with value: 0.8137882018479033.\u001b[0m\n",
      "\u001b[32m[I 2022-09-06 20:25:02,109]\u001b[0m Trial 180 finished with value: 0.8024164889836531 and parameters: {'classifier': 'AdaBoost', 'n_estimators': 30, 'learning_rate': 0.5790675823667785}. Best is trial 23 with value: 0.8137882018479033.\u001b[0m\n",
      "\u001b[32m[I 2022-09-06 20:25:02,192]\u001b[0m Trial 181 finished with value: 0.8073916133617626 and parameters: {'classifier': 'AdaBoost', 'n_estimators': 20, 'learning_rate': 0.48940002570337376}. Best is trial 23 with value: 0.8137882018479033.\u001b[0m\n",
      "\u001b[32m[I 2022-09-06 20:25:02,239]\u001b[0m Trial 182 finished with value: 0.8137882018479033 and parameters: {'classifier': 'AdaBoost', 'n_estimators': 10, 'learning_rate': 0.5640930526810467}. Best is trial 23 with value: 0.8137882018479033.\u001b[0m\n",
      "\u001b[32m[I 2022-09-06 20:25:02,360]\u001b[0m Trial 183 finished with value: 0.8038379530916845 and parameters: {'classifier': 'AdaBoost', 'n_estimators': 30, 'learning_rate': 0.5641826316975989}. Best is trial 23 with value: 0.8137882018479033.\u001b[0m\n",
      "\u001b[32m[I 2022-09-06 20:25:02,408]\u001b[0m Trial 184 finished with value: 0.8002842928216063 and parameters: {'classifier': 'AdaBoost', 'n_estimators': 10, 'learning_rate': 0.6462545819199258}. Best is trial 23 with value: 0.8137882018479033.\u001b[0m\n",
      "\u001b[32m[I 2022-09-06 20:25:02,454]\u001b[0m Trial 185 finished with value: 0.7924662402274343 and parameters: {'classifier': 'AdaBoost', 'n_estimators': 10, 'learning_rate': 0.7743876968161716}. Best is trial 23 with value: 0.8137882018479033.\u001b[0m\n",
      "\u001b[32m[I 2022-09-06 20:25:02,539]\u001b[0m Trial 186 finished with value: 0.806680881307747 and parameters: {'classifier': 'AdaBoost', 'n_estimators': 20, 'learning_rate': 0.7033502951254995}. Best is trial 23 with value: 0.8137882018479033.\u001b[0m\n",
      "<timed exec>:20: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use :func:`~optuna.trial.Trial.suggest_float` instead.\n",
      "/Users/ivanpua/opt/anaconda3/envs/ml/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "\u001b[32m[I 2022-09-06 20:25:02,645]\u001b[0m Trial 187 finished with value: 0.7398720682302772 and parameters: {'classifier': 'Logistic', 'penalty': 'l1', 'logistic-regularization': 3.3893955552774653}. Best is trial 23 with value: 0.8137882018479033.\u001b[0m\n",
      "\u001b[32m[I 2022-09-06 20:25:02,731]\u001b[0m Trial 188 finished with value: 0.8017057569296375 and parameters: {'classifier': 'AdaBoost', 'n_estimators': 20, 'learning_rate': 0.559238747219664}. Best is trial 23 with value: 0.8137882018479033.\u001b[0m\n",
      "\u001b[32m[I 2022-09-06 20:25:02,819]\u001b[0m Trial 189 finished with value: 0.8031272210376688 and parameters: {'classifier': 'AdaBoost', 'n_estimators': 20, 'learning_rate': 0.5483826581715018}. Best is trial 23 with value: 0.8137882018479033.\u001b[0m\n",
      "\u001b[32m[I 2022-09-06 20:25:02,867]\u001b[0m Trial 190 finished with value: 0.8052594171997157 and parameters: {'classifier': 'AdaBoost', 'n_estimators': 10, 'learning_rate': 0.5052149153900116}. Best is trial 23 with value: 0.8137882018479033.\u001b[0m\n",
      "\u001b[32m[I 2022-09-06 20:25:02,989]\u001b[0m Trial 191 finished with value: 0.8081023454157783 and parameters: {'classifier': 'AdaBoost', 'n_estimators': 30, 'learning_rate': 0.47377824642984634}. Best is trial 23 with value: 0.8137882018479033.\u001b[0m\n",
      "\u001b[32m[I 2022-09-06 20:25:03,111]\u001b[0m Trial 192 finished with value: 0.8073916133617626 and parameters: {'classifier': 'AdaBoost', 'n_estimators': 30, 'learning_rate': 0.6320533123449984}. Best is trial 23 with value: 0.8137882018479033.\u001b[0m\n",
      "\u001b[32m[I 2022-09-06 20:25:03,238]\u001b[0m Trial 193 finished with value: 0.7910447761194029 and parameters: {'classifier': 'AdaBoost', 'n_estimators': 30, 'learning_rate': 1.9496076725650442}. Best is trial 23 with value: 0.8137882018479033.\u001b[0m\n",
      "\u001b[32m[I 2022-09-06 20:25:03,288]\u001b[0m Trial 194 finished with value: 0.8137882018479033 and parameters: {'classifier': 'AdaBoost', 'n_estimators': 10, 'learning_rate': 0.5979430514870808}. Best is trial 23 with value: 0.8137882018479033.\u001b[0m\n",
      "\u001b[32m[I 2022-09-06 20:25:03,337]\u001b[0m Trial 195 finished with value: 0.8137882018479033 and parameters: {'classifier': 'AdaBoost', 'n_estimators': 10, 'learning_rate': 0.5880310912605083}. Best is trial 23 with value: 0.8137882018479033.\u001b[0m\n",
      "\u001b[32m[I 2022-09-06 20:25:03,386]\u001b[0m Trial 196 finished with value: 0.8137882018479033 and parameters: {'classifier': 'AdaBoost', 'n_estimators': 10, 'learning_rate': 0.599845050374936}. Best is trial 23 with value: 0.8137882018479033.\u001b[0m\n",
      "\u001b[32m[I 2022-09-06 20:25:03,434]\u001b[0m Trial 197 finished with value: 0.7846481876332623 and parameters: {'classifier': 'AdaBoost', 'n_estimators': 10, 'learning_rate': 0.739028859487505}. Best is trial 23 with value: 0.8137882018479033.\u001b[0m\n",
      "\u001b[32m[I 2022-09-06 20:25:03,484]\u001b[0m Trial 198 finished with value: 0.8002842928216063 and parameters: {'classifier': 'AdaBoost', 'n_estimators': 10, 'learning_rate': 0.6557761749206524}. Best is trial 23 with value: 0.8137882018479033.\u001b[0m\n",
      "\u001b[32m[I 2022-09-06 20:25:03,571]\u001b[0m Trial 199 finished with value: 0.7967306325515281 and parameters: {'classifier': 'AdaBoost', 'n_estimators': 20, 'learning_rate': 0.5833321883213624}. Best is trial 23 with value: 0.8137882018479033.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of finished trials: 200\n",
      "Best trial:\n",
      "  Value: 0.8137882018479033\n",
      "  Params: \n",
      "    classifier: AdaBoost\n",
      "    n_estimators: 10\n",
      "    learning_rate: 0.555344080589061\n",
      "CPU times: user 51.5 s, sys: 10.3 s, total: 1min 1s\n",
      "Wall time: 48.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def objective(trial):\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "\n",
    "    # Selecting the best model out of these two candidates\n",
    "    classifier_name = trial.suggest_categorical(\"classifier\", [\"Logistic\", \"AdaBoost\"])\n",
    "    if classifier_name == \"Logistic\":\n",
    "        \n",
    "        # Add parameters here\n",
    "        penalty = trial.suggest_categorical('penalty', ['l2', 'l1'])\n",
    "        if penalty == 'l1':\n",
    "            solver = 'saga'\n",
    "        else:\n",
    "            solver = 'lbfgs'\n",
    "        regularization = trial.suggest_uniform('logistic-regularization', 0.01, 10)\n",
    "        model = LogisticRegression(penalty=penalty, \n",
    "                                   C=regularization, \n",
    "                                   solver=solver, \n",
    "                                   random_state=0)\n",
    "    else:\n",
    "        \n",
    "        # Add parameters here\n",
    "        ada_n_estimators = trial.suggest_int(\"n_estimators\", 10, 500, step = 10)\n",
    "        ada_learning_rate = trial.suggest_float(\"learning_rate\", 0.1, 3)\n",
    "        \n",
    "        model = sklearn.ensemble.AdaBoostClassifier(\n",
    "            n_estimators=ada_n_estimators,\n",
    "            learning_rate = ada_learning_rate,\n",
    "            random_state=0\n",
    "        )\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    recall = model.score(X_test, y_test)\n",
    "    return recall\n",
    "\n",
    "\n",
    "# 3. Create a study object and optimize the objective function.\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=200)\n",
    "\n",
    "print(\"Number of finished trials: {}\".format(len(study.trials)))\n",
    "\n",
    "print(\"Best trial:\")\n",
    "trial = study.best_trial\n",
    "\n",
    "print(\"  Value: {}\".format(trial.value))\n",
    "\n",
    "print(\"  Params: \")\n",
    "for key, value in trial.params.items():\n",
    "    print(\"    {}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "492ee680",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f5f63ff3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (recall) is 0.8138\n",
      "\n",
      "CPU times: user 67.1 ms, sys: 3.18 ms, total: 70.3 ms\n",
      "Wall time: 69.4 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Adaboost\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "model = AdaBoostClassifier(n_estimators=10, \n",
    "                           learning_rate = 0.555344080589061,\n",
    "                           random_state=0)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "recall = model.score(X_test, y_test)\n",
    "print(f\"Accuracy (recall) is {round(recall, 4)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a25dcf96",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
