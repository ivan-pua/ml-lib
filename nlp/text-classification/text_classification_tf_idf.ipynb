{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d5c1d8f",
   "metadata": {},
   "source": [
    "# Text Classification with TF IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6fe29f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ivanpua/opt/anaconda3/envs/nlp-pytorch-legacy/lib/python3.8/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.1\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "# Data processing\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "# Visualization\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Text processing\n",
    "import re\n",
    "import nltk\n",
    "\n",
    "# Various\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d7156b",
   "metadata": {},
   "source": [
    "# EDA of Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51c30dcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>According to Gran , the company has no plans t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Technopolis plans to develop in stages an area...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>The international electronic industry company ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>With the new production plant the company woul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>According to the company 's updated strategy f...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                               text\n",
       "0          1  According to Gran , the company has no plans t...\n",
       "1          1  Technopolis plans to develop in stages an area...\n",
       "2          0  The international electronic industry company ...\n",
       "3          2  With the new production plant the company woul...\n",
       "4          2  According to the company 's updated strategy f..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select the dataset for the analysis\n",
    "df = pd.read_csv(\"all-data-v1.csv\")\n",
    "\n",
    "# Show the data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9bd83f77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of news: 4846\n",
      "----------------------------------------\n",
      "Split by category:\n",
      "1    2879\n",
      "2    1363\n",
      "0     604\n",
      "Name: sentiment, dtype: int64\n",
      "----------------------------------------\n",
      "Number of categories: 3\n"
     ]
    }
   ],
   "source": [
    "print('Total number of news: {}'.format(len(df)))\n",
    "print(40*'-')\n",
    "print('Split by category:')\n",
    "print(df[\"sentiment\"].value_counts())\n",
    "print(40*'-')\n",
    "nr_categories = len(df[\"sentiment\"].unique())\n",
    "print(\"Number of categories: {n}\".format(n=nr_categories))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43eac634",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "362ddb4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/ivanpua/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "stopWords = stopwords.words('english') # from NLTK\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c6ca4e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a Function to clean up the reviews \n",
    "def utils_preprocess_text(text, \n",
    "                          flg_stemm=False, \n",
    "                          flg_lemm=False, \n",
    "                          lst_stopwords=None):\n",
    "    # Clean (convert to lowercase and remove punctuations and characters and then strip)\n",
    "    # The function is not optimized for speed but split into various steps for pedagogical purpose\n",
    "    text = str(text).lower()\n",
    "    text = re.sub(\"[!?.,@#$%\\^*()';:/~<>]\", '', text) # remove punctuations\n",
    "    text = text.replace('-', ' ') # replace \n",
    "    text = text.replace(\"&\", 'and') # replace\n",
    "    text = text.strip()\n",
    "\n",
    "    # Tokenize (convert from string to list)\n",
    "    lst_text = text.split()\n",
    "    # remove Stopwords\n",
    "    if lst_stopwords is not None:\n",
    "        lst_text = [word for word in lst_text if word not in lst_stopwords]\n",
    "\n",
    "    # Stemming (remove -ing, -ly, ...)\n",
    "    if flg_stemm == True:\n",
    "        ps = nltk.stem.porter.PorterStemmer()\n",
    "        lst_text = [ps.stem(word) for word in lst_text]\n",
    "\n",
    "    # Lemmatisation (convert the word into root word)\n",
    "    if flg_lemm == True:\n",
    "        lem = nltk.stem.wordnet.WordNetLemmatizer()\n",
    "        lst_text = [lem.lemmatize(word) for word in lst_text]\n",
    "\n",
    "    # back to string from list\n",
    "    text = \" \".join(lst_text)\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a67672a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "      <th>text_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>According to Gran , the company has no plans t...</td>\n",
       "      <td>accord gran compani plan move product russia a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Technopolis plans to develop in stages an area...</td>\n",
       "      <td>technopoli plan develop stage area le 100000 s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>The international electronic industry company ...</td>\n",
       "      <td>intern electron industri compani elcoteq laid ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>With the new production plant the company woul...</td>\n",
       "      <td>new product plant compani would increas capac ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>According to the company 's updated strategy f...</td>\n",
       "      <td>accord compani updat strategi year 2009 2012 b...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                               text  \\\n",
       "0          1  According to Gran , the company has no plans t...   \n",
       "1          1  Technopolis plans to develop in stages an area...   \n",
       "2          0  The international electronic industry company ...   \n",
       "3          2  With the new production plant the company woul...   \n",
       "4          2  According to the company 's updated strategy f...   \n",
       "\n",
       "                                          text_clean  \n",
       "0  accord gran compani plan move product russia a...  \n",
       "1  technopoli plan develop stage area le 100000 s...  \n",
       "2  intern electron industri compani elcoteq laid ...  \n",
       "3  new product plant compani would increas capac ...  \n",
       "4  accord compani updat strategi year 2009 2012 b...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's apply this function to the whole corpus\n",
    "df[\"text_clean\"] = df[\"text\"].apply(\n",
    "    lambda x: utils_preprocess_text(x, \n",
    "                                    flg_stemm=True, \n",
    "                                    flg_lemm=True, \n",
    "                                    lst_stopwords=stopWords\n",
    "                                   ))\n",
    "\n",
    "# Let's look at the output\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "36967f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# Renaming, Input -> X, Output -> y\n",
    "X = df['text_clean']\n",
    "y = df['sentiment']\n",
    "# Split into Training and Test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=0.3, \n",
    "                                                    random_state=42, \n",
    "                                                    stratify=df['sentiment']\n",
    "                                                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb427dc",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7134bb46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>TfidfVectorizer(max_features=15000, ngram_range=(1, 2))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer(max_features=15000, ngram_range=(1, 2))</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "TfidfVectorizer(max_features=15000, ngram_range=(1, 2))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "corpus = X_train\n",
    "# Initizalize the vectorizer with max nr words \n",
    "# and ngrams (1: single words, 2: two words in a row)\n",
    "vectorizer_tfidf = TfidfVectorizer(max_features=15000, \n",
    "                                   ngram_range=(1,2))\n",
    "\n",
    "# Fit the vectorizer to the training data\n",
    "vectorizer_tfidf.fit(corpus)\n",
    "TfidfVectorizer(max_features=15000, ngram_range=(1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "688db6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_tfidf = LogisticRegression()\n",
    "model_tfidf = Pipeline([(\"vectorizer\", vectorizer_tfidf), (\"classifier\", classifier_tfidf)])\n",
    "\n",
    "start_time = datetime.now()\n",
    "model_tfidf.fit(X_train, y_train)\n",
    "end_time = datetime.now()\n",
    "\n",
    "training_time_tfidf = (end_time - start_time).total_seconds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c5b89881",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Training data: 87.1%\n",
      "Accuracy Test data: 72.4%\n",
      "Training time: 1.0s\n"
     ]
    }
   ],
   "source": [
    "predicted_train_tfidf = model_tfidf.predict(X_train)\n",
    "accuracy_train_tfidf = accuracy_score(y_train, predicted_train_tfidf)\n",
    "print('Accuracy Training data: {:.1%}'.format(accuracy_train_tfidf))\n",
    "\n",
    "predicted_test_tfidf = model_tfidf.predict(X_test)\n",
    "accuracy_test_tfidf = accuracy_score(y_test, predicted_test_tfidf)\n",
    "accuracy_tfidf = accuracy_test_tfidf\n",
    "print('Accuracy Test data: {:.1%}'.format(accuracy_test_tfidf))\n",
    "\n",
    "print('Training time: {:.1f}s'.format(training_time_tfidf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9600a867",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes of the model:  ['Negative', 'Neutral', 'Positive']\n",
      "--------------------------------------------------------------------------------\n",
      "Shape of the coefficients of the model (categories x vocabulary size):  (3, 15000)\n",
      "--------------------------------------------------------------------------------\n",
      "Negative: cut, lay, result, compar, staff, half, drop, lower, fell, decreas, \n",
      "--------------------------------------------------------------------------------\n",
      "Neutral: rang, sell, stake, design, busi, avail, disclos, valu, approxim, includ, \n",
      "--------------------------------------------------------------------------------\n",
      "Positive: lead, said, posit, cooper, expand, sign, grew, improv, rose, increas, \n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "classes = ['Negative', 'Neutral', 'Positive']\n",
    "\n",
    "print('Classes of the model: ', classes)\n",
    "print(80*'-')\n",
    "print('Shape of the coefficients of the model (categories x vocabulary size): ',classifier_tfidf.coef_.shape)\n",
    "print(80*'-')\n",
    "NN = 10\n",
    "# Get the 10 (here: NN, which you can adjust yourself) ids of the words with highest weights per category\n",
    "top_words = np.argsort(classifier_tfidf.coef_,axis=1)[:,-NN:]\n",
    "\n",
    "# Get the vocabulary of the model (mapping of words to ids):\n",
    "voc = vectorizer_tfidf.vocabulary_\n",
    "# Get the inverse vocabulary to map the ids of the words to the words:\n",
    "inv_voc = {v: k for k, v in voc.items()}\n",
    "\n",
    "# Get for each category (=class) the top ten words\n",
    "for n, w in enumerate(classes):\n",
    "    t = f\"{w}: \"\n",
    "    for i in range(NN):\n",
    "        t += inv_voc[top_words[n,i]]\n",
    "        if i!=NN:\n",
    "            t+=', '\n",
    "    print(t)\n",
    "    print(80*'-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4cefa6a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp-torch-legacy",
   "language": "python",
   "name": "nlp-torch-legacy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
